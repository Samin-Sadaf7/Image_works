{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samin-Sadaf7/Image_works/blob/main/Finetune_EfficientDet_for_Traffic_Sign_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzdE1K54pNJH"
      },
      "source": [
        "# Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cohpWPCJpNJI"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVmbZ8eia-hX",
        "outputId": "81a3ce48-cb3e-4dab-e37f-c07de3cd5ef8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9CVvHQGpNJU",
        "outputId": "32e87561-8f0e-4c81-de05-0ee3c5e89c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzSPT1OxpNJg"
      },
      "source": [
        "## Download the code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mOcS9Pk6XBL",
        "outputId": "2cd2768c-d22b-4e4b-f9ff-d5aafcf01220"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 97475, done.\u001b[K\n",
            "remote: Counting objects: 100% (755/755), done.\u001b[K\n",
            "remote: Compressing objects: 100% (350/350), done.\u001b[K\n",
            "remote: Total 97475 (delta 462), reused 623 (delta 398), pack-reused 96720\u001b[K\n",
            "Receiving objects: 100% (97475/97475), 613.70 MiB | 26.57 MiB/s, done.\n",
            "Resolving deltas: 100% (70880/70880), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnJI65a7pNJg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aad535bd-c84a-403d-eb75-8f04b1df3613"
      },
      "source": [
        "if not os.path.isdir(\"automl\"):\n",
        "    # clone the repository\n",
        "    !git clone --depth 1 https://github.com/google/automl\n",
        "\n",
        "    # checkout to the latest commit that we used when we're creating this notebook\n",
        "    %cd automl\n",
        "    !git checkout 1ec78d22aa9f8b7d33b9cf3a177e05dcc6b4a093\n",
        "\n",
        "    # change the working directory\n",
        "    %cd efficientdet\n",
        "\n",
        "    # install required packages\n",
        "    # if it fails to install pycocotools, please manually remove pycocotools from requirements.txt and run again\n",
        "    %pip install -r requirements.txt\n",
        "    %pip install -U \"git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\"\n",
        "\n",
        "PROJ_DIR = os.path.join(\"/content\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'automl'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
            "remote: Total 181 (delta 16), reused 71 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (181/181), 13.79 MiB | 18.83 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/content/automl\n",
            "fatal: reference is not a tree: 1ec78d22aa9f8b7d33b9cf3a177e05dcc6b4a093\n",
            "/content/automl/efficientdet\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI (from -r requirements.txt (line 13))\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-8eg43p0l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-8eg43p0l\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.9.4)\n",
            "Requirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
            "Collecting numpy<1.24.0,>=1.19.4 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.5.0 (from -r requirements.txt (line 5))\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (6.0.1)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.15.0)\n",
            "Collecting tensorflow-addons>=0.18.0 (from -r requirements.txt (line 9))\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.16.1)\n",
            "Collecting neural-structured-learning>=1.3.1 (from -r requirements.txt (line 11))\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.15.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.18.0->-r requirements.txt (line 9))\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.11->-r requirements.txt (line 10)) (2.15.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from neural-structured-learning>=1.3.1->-r requirements.txt (line 11)) (23.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from neural-structured-learning>=1.3.1->-r requirements.txt (line 11)) (1.11.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.10.0->-r requirements.txt (line 8)) (3.2.2)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=375617 sha256=023d8286eb4370da67be5c990de01e3aa6e71b25a73a227cbfeaf6b967818e31\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yrwtw_uc/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: typeguard, Pillow, numpy, tensorflow-addons, neural-structured-learning, pycocotools\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.8\n",
            "    Uninstalling pycocotools-2.0.8:\n",
            "      Successfully uninstalled pycocotools-2.0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.4.0 neural-structured-learning-1.4.0 numpy-1.23.5 pycocotools-2.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "92d158cf5f45412e8af28cd3f6247a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-8zbrxx50\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-8zbrxx50\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (67.7.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.0.10)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApnsQpVlpNJn"
      },
      "source": [
        "## Download the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zQTNbfvpNJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8c9170-2f46-4efc-a5d4-8f1fbb69a2a2"
      },
      "source": [
        "MODEL = \"efficientdet-d1\"\n",
        "if not os.path.exists(f\"{MODEL}.tar.gz\"):\n",
        "    !curl -O https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco2/{MODEL}.tar.gz\n",
        "    !tar xvzf {MODEL}.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 46.5M  100 46.5M    0     0  18.2M      0  0:00:02  0:00:02 --:--:-- 18.2M\n",
            "efficientdet-d1/\n",
            "efficientdet-d1/model.meta\n",
            "efficientdet-d1/model.index\n",
            "efficientdet-d1/checkpoint\n",
            "efficientdet-d1/d1_coco_val.txt\n",
            "efficientdet-d1/d1_coco_test-dev2017.txt\n",
            "efficientdet-d1/model.data-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42edvYCbLn14",
        "outputId": "db35806e-b53a-496a-9b01-ff6f6ea97dde"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 97475, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 97475 (delta 21), reused 32 (delta 16), pack-reused 97433\u001b[K\n",
            "Receiving objects: 100% (97475/97475), 613.51 MiB | 23.13 MiB/s, done.\n",
            "Resolving deltas: 100% (70962/70962), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models/research\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!pip install --use-feature=2020-resolver ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLoY7Gx6Mp_f",
        "outputId": "893a4229-95c9-498b-d3d1-b29eac98cb7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/models/research\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "option --use-feature: invalid choice: '2020-resolver' (choose from 'fast-deps', 'truststore', 'no-binary-enable-wheel-cache')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtZxjTLGpNJu"
      },
      "source": [
        "# Preprocess the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qHDsjDpNJv"
      },
      "source": [
        "## Preprocessing parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    'Crossroads',\n",
        "    'no use of horn',\n",
        "    'Road Hump',\n",
        "    'Narrow Bridge',\n",
        "    'speed limit 40 km/h',\n",
        "    'Side Road Right',\n",
        "    'School',\n",
        "    'Sharp Bend To The Left',\n",
        "    'speed limit 80 km/h',\n",
        "    'Side Road Left',\n",
        "    'PEDESTRIAN CROSSING',\n",
        "    'No Overtaking',\n",
        "    'Sharp Bend To The Right',\n",
        "    'Speed Limit 60 km/h',\n",
        "    'U Turn'\n",
        "]\n",
        "\n",
        "with open('label_map.pbtxt', 'w') as f:\n",
        "    for i, label in enumerate(labels, 1):\n",
        "        f.write('item {\\n')\n",
        "        f.write('\\tid: {}\\n'.format(i))\n",
        "        f.write('\\tname: \"{}\"\\n'.format(label))\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "S-1n1cLHyLUQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classnames.txt','w') as f:\n",
        "  for label in labels:\n",
        "      f.write(label)\n",
        "      f.write(',')"
      ],
      "metadata": {
        "id": "c7UH7LFeHJAZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_yUGVhMLm8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/create_tfrecord.py --data_dir='/path/to/train' --output_path='/path/to/output/train.record' --label_map_path='/path/to/label_map.pbtxt' --classes_file='/path/to/classnames.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IobIXfqKDWYl",
        "outputId": "b11a3af9-8abe-47e1-bfa9-75924893ed4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-15 06:57:09.833617: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-15 06:57:09.833695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-15 06:57:09.835760: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-15 06:57:09.848462: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-15 06:57:11.749772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/create_tfrecord.py\", line 13, in <module>\n",
            "    from object_detection.utils import dataset_util\n",
            "ModuleNotFoundError: No module named 'object_detection'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJ_DIR = os.path.join(\"/content/gdrive/MyDrive/Dataset- -Conference\")"
      ],
      "metadata": {
        "id": "iv5_BOs25nAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E-vgPi5pNJw"
      },
      "source": [
        "DATASET_DIR = os.path.join(PROJ_DIR)\n",
        "TFRECORD_DIR = os.path.join(PROJ_DIR, \"tfrecords\")\n",
        "\n",
        "TRAIN_SET_FILE = os.path.join(DATASET_DIR, \"train\")\n",
        "TRAIN_SET_FILE = \"/content/gdrive/MyDrive/Dataset- -Conference/train/train.txt\"\n",
        "VAL_SET_FILE = os.path.join(DATASET_DIR, \"val\")\n",
        "TEST_SET_FILE = os.path.join(DATASET_DIR,  \"test\")\n",
        "\n",
        "SAMPLES_PER_FILE = 10000   # we only construct a subset, in total there are 100,000 samples in each set\n",
        "\n",
        "LP_CLASS = 1   # class id for the license plate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vdTvdwhpNJ2"
      },
      "source": [
        "import re\n",
        "import hashlib\n",
        "\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.compat.v1.python_io import tf_record_iterator\n",
        "\n",
        "\n",
        "def filename_to_annotation(filename):\n",
        "    \"\"\"\n",
        "    Annotations are embedded in file name.\n",
        "\n",
        "    A sample image name is \"025-95_113-154&383_386&473-386&473_177&454_154&383_363&402-0_0_22_27_27_33_16-37-15.jpg\". Each name can be splited into seven fields. Those fields are explained as follows.\n",
        "\n",
        "        Area: Area ratio of license plate area to the entire picture area.\n",
        "\n",
        "        Tilt degree: Horizontal tilt degree and vertical tilt degree.\n",
        "\n",
        "        Bounding box coordinates: The coordinates of the left-up and the right-bottom vertices.\n",
        "\n",
        "        Four vertices locations: The exact (x, y) coordinates of the four vertices of LP in the whole image. These coordinates start from the right-bottom vertex.\n",
        "\n",
        "        License plate number: Each image in CCPD has only one LP. Each LP number is comprised of a Chinese character, a letter, and five letters or numbers. A valid Chinese license plate consists of seven characters: province (1 character), alphabets (1 character), alphabets+digits (5 characters). \"0_0_22_27_27_33_16\" is the index of each character. These three arrays are defined as follows. The last character of each array is letter O rather than a digit 0. We use O as a sign of \"no character\" because there is no O in Chinese license plate characters.\n",
        "\n",
        "        Brightness: The brightness of the license plate region.\n",
        "\n",
        "        Blurriness: The Blurriness of the license plate region.\n",
        "    \"\"\"\n",
        "\n",
        "    m = re.match(\n",
        "        r'^'\n",
        "        r'([0-9]+)-'\n",
        "        r'([0-9]+)_([0-9]+)-'\n",
        "        r'([0-9]+)&([0-9]+)_([0-9]+)&([0-9]+)-'\n",
        "        r'([0-9]+)&([0-9]+)_([0-9]+)&([0-9]+)_([0-9]+)&([0-9]+)_([0-9]+)&([0-9]+)-'\n",
        "        r'([0-9_]+)-'\n",
        "        r'([0-9]+)-'\n",
        "        r'([0-9]+)'\n",
        "        r'.png$'\n",
        "        , filename\n",
        "    )\n",
        "\n",
        "    if m:\n",
        "        m = m.groups()\n",
        "        anno = {\n",
        "            \"area_ratio\": int(m[0]),\n",
        "            \"tilt_h\": int(m[1]),\n",
        "            \"tile_v\": int(m[2]),\n",
        "            \"bbox\": {\n",
        "                \"left\": int(m[3]),\n",
        "                \"top\": int(m[4]),\n",
        "                \"right\": int(m[5]),\n",
        "                \"bottom\": int(m[6])\n",
        "            },\n",
        "            \"lp\": str(m[15]),\n",
        "            \"brightness\": int(m[16]),\n",
        "            \"blurriness\": int(m[17])\n",
        "        }\n",
        "        assert anno[\"bbox\"][\"left\"] < anno[\"bbox\"][\"right\"]\n",
        "        assert anno[\"bbox\"][\"top\"] < anno[\"bbox\"][\"bottom\"]\n",
        "    else:\n",
        "        raise ValueError(\"the filename cannot be resolved\")\n",
        "\n",
        "    return anno\n",
        "\n",
        "\n",
        "def create_example(id, filepath, annotation):\n",
        "    img_raw = open(filepath, \"rb\").read()\n",
        "    key = hashlib.sha256(img_raw).hexdigest()\n",
        "    filename = os.path.basename(filepath)\n",
        "    width, height = PIL.Image.open(filepath).size\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        \"image/height\": tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        \"image/width\": tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        \"image/filename\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode(\"utf-8\")])),\n",
        "        \"image/source_id\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(id).encode(\"utf-8\")])),\n",
        "        \"image/key/sha256\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode(\"utf-8\")])),\n",
        "        \"image/encoded\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
        "        \"image/format\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"jpg\".encode(\"utf8\")])),\n",
        "        \"image/object/bbox/xmin\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"bbox\"][\"left\"] / width])),\n",
        "        \"image/object/bbox/xmax\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"bbox\"][\"right\"] / width])),\n",
        "        \"image/object/bbox/ymin\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"bbox\"][\"top\"] / height])),\n",
        "        \"image/object/bbox/ymax\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"bbox\"][\"bottom\"] / height])),\n",
        "        \"image/object/class/text\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"license_plate\".encode(\"utf-8\")])),\n",
        "        \"image/object/class/label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[LP_CLASS])),\n",
        "        \"image/object/difficult\": tf.train.Feature(int64_list=tf.train.Int64List(value=[0])),\n",
        "        \"image/object/truncated\": tf.train.Feature(int64_list=tf.train.Int64List(value=[0])),\n",
        "        \"image/object/view\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"Unspecified\".encode(\"utf-8\")])),\n",
        "    }))\n",
        "    return example\n",
        "\n",
        "\n",
        "def create_tfrecord(dataset_path, output_path, samples_per_file):\n",
        "    print(f\"creating {dataset_path} at {output_path}\")\n",
        "\n",
        "    # create the output directory if not exist\n",
        "    output_dir = os.path.dirname(output_path)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # read the dataset\n",
        "    with open(dataset_path, \"r\") as fread:\n",
        "        lines = fread.read().splitlines()\n",
        "\n",
        "    # write examples into tfrecord\n",
        "    fid = 0\n",
        "    partition_path = output_path + f\"-{fid:02d}\"\n",
        "    tfwriter = tf.io.TFRecordWriter(partition_path)\n",
        "    for i, subpath in enumerate(lines):\n",
        "        if (i + 1) % samples_per_file == 0:\n",
        "            fid += 1\n",
        "            partition_path = output_path + f\"-{fid:02d}\"\n",
        "            tfwriter.close()\n",
        "            tfwriter = tf.io.TFRecordWriter(partition_path)\n",
        "\n",
        "        filepath = os.path.join(DATASET_DIR, subpath)\n",
        "        filename = os.path.basename(filepath)\n",
        "        annotation = filename_to_annotation(filename)\n",
        "        example = create_example(i + 1, filepath, annotation)\n",
        "        tfwriter.write(example.SerializeToString())\n",
        "    tfwriter.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def parse_xml(annotation_path):\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "    bndbox = root.find(\".//bndbox\")\n",
        "    obj_name = root.find(\".//object/name\").text\n",
        "\n",
        "    annotation = {\n",
        "        \"left\": int(bndbox.find(\"xmin\").text),\n",
        "        \"top\": int(bndbox.find(\"ymin\").text),\n",
        "        \"right\": int(bndbox.find(\"xmax\").text),\n",
        "        \"bottom\": int(bndbox.find(\"ymax\").text),\n",
        "        \"class_name\": obj_name\n",
        "    }\n",
        "\n",
        "    return annotation\n",
        "\n",
        "\n",
        "def create_example(id, image_path, annotation):\n",
        "    img_raw = open(image_path, \"rb\").read()\n",
        "    key = hashlib.sha256(img_raw).hexdigest()\n",
        "    filename = os.path.basename(image_path)\n",
        "    width, height = PIL.Image.open(image_path).size\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        \"image/height\": tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        \"image/width\": tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        \"image/filename\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode(\"utf-8\")])),\n",
        "        \"image/source_id\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(id).encode(\"utf-8\")])),\n",
        "        \"image/key/sha256\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode(\"utf-8\")])),\n",
        "        \"image/encoded\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
        "        \"image/format\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"jpg\".encode(\"utf-8\")])),\n",
        "        \"image/object/bbox/xmin\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"left\"] / width])),\n",
        "        \"image/object/bbox/xmax\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"right\"] / width])),\n",
        "        \"image/object/bbox/ymin\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"top\"] / height])),\n",
        "        \"image/object/bbox/ymax\": tf.train.Feature(float_list=tf.train.FloatList(value=[annotation[\"bottom\"] / height])),\n",
        "        \"image/object/class/text\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[annotation[\"class_name\"].encode(\"utf-8\")])),\n",
        "        \"image/object/class/label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[1])),  # You might want to map this to specific labels\n",
        "        \"image/object/difficult\": tf.train.Feature(int64_list=tf.train.Int64List(value=[0])),\n",
        "        \"image/object/truncated\": tf.train.Feature(int64_list=tf.train.Int64List(value=[0])),\n",
        "        \"image/object/view\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"Unspecified\".encode(\"utf-8\")])),\n",
        "    }))\n",
        "    return example\n",
        "\n",
        "\n",
        "def create_tfrecord(image_dir, annotation_dir, output_path, subset):\n",
        "    print(f\"Creating TFRecord file for {subset} dataset in {image_dir} at {output_path}\")\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    output_dir = os.path.dirname(output_path)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "    partition_path = output_path + f\"-{subset}.tfrecord\"\n",
        "    tfwriter = tf.io.TFRecordWriter(partition_path)\n",
        "\n",
        "    for i, filename in enumerate(files):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        annotation_path = os.path.join(annotation_dir, os.path.splitext(filename)[0] + '.xml')\n",
        "\n",
        "        if not os.path.exists(annotation_path):\n",
        "            print(f\"Annotation file for {filename} does not exist. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        annotation = parse_xml(annotation_path)\n",
        "        example = create_example(i + 1, image_path, annotation)\n",
        "        tfwriter.write(example.SerializeToString())\n",
        "\n",
        "    tfwriter.close()\n",
        "    print(f\"TFRecord file for {subset} created successfully.\")"
      ],
      "metadata": {
        "id": "vzUY_7dliThz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from difflib import get_close_matches\n",
        "\n",
        "def get_closest_label(class_name, label_map):\n",
        "    labels = list(label_map.values())\n",
        "    closest_match = get_close_matches(class_name, labels, n=1)\n",
        "    return closest_match[0] if closest_match else None\n",
        "\n",
        "def generate_filename_from_annotation(image_path, annotation_path, label_map):\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    filename = os.path.basename(image_path)\n",
        "    image_size = root.find(\"size\")\n",
        "    width = int(image_size.find(\"width\").text)\n",
        "    height = int(image_size.find(\"height\").text)\n",
        "    depth = int(image_size.find(\"depth\").text)\n",
        "\n",
        "    objects = root.findall(\"object\")\n",
        "\n",
        "    area_ratio = 1  # Placeholder, calculate if needed\n",
        "    tilt_h = 0  # Placeholder, calculate if needed\n",
        "    tilt_v = 0  # Placeholder, calculate if needed\n",
        "\n",
        "    bbox_str = \"\"\n",
        "    vertices_str = \"\"\n",
        "    class_ids = []\n",
        "    for obj in objects:\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bndbox.find(\"xmin\").text)\n",
        "        ymin = int(bndbox.find(\"ymin\").text)\n",
        "        xmax = int(bndbox.find(\"xmax\").text)\n",
        "        ymax = int(bndbox.find(\"ymax\").text)\n",
        "\n",
        "        class_name = obj.find(\"name\").text\n",
        "        closest_label = get_closest_label(class_name, label_map)\n",
        "        if closest_label:\n",
        "            class_id = list(label_map.keys())[list(label_map.values()).index(closest_label)]\n",
        "            class_ids.append(class_id)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        bbox_str += f\"{xmin}&{ymin}_{xmax}&{ymax}-\"\n",
        "        vertices_str += f\"{xmax}&{ymax}_{xmin}&{ymax}_{xmin}&{ymin}_{xmax}&{ymin}-\"\n",
        "\n",
        "    if not class_ids:\n",
        "        return None\n",
        "\n",
        "    class_ids_str = \"_\".join(map(str, class_ids))\n",
        "    brightness = 0  # Placeholder, calculate if needed\n",
        "    blurriness = 0  # Placeholder, calculate if needed\n",
        "\n",
        "    annotation_str = f\"{area_ratio}-{tilt_h}_{tilt_v}-{bbox_str[:-1]}-{vertices_str[:-1]}-{class_ids_str}-{brightness}-{blurriness}.jpg\"\n",
        "\n",
        "    return annotation_str\n",
        "\n",
        "def generate_annotation_file(train_dir, output_file, label_map):\n",
        "    images_dir = os.path.join(train_dir, 'images')\n",
        "    annotations_dir = os.path.join(train_dir, 'annotation')\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        for image_filename in os.listdir(images_dir):\n",
        "            if image_filename.endswith('.jpg') or image_filename.endswith('.png'):\n",
        "                image_path = os.path.join(images_dir, image_filename)\n",
        "                annotation_filename = os.path.splitext(image_filename)[0] + '.xml'\n",
        "                annotation_path = os.path.join(annotations_dir, annotation_filename)\n",
        "\n",
        "                if os.path.exists(annotation_path):\n",
        "                    annotation_str = generate_filename_from_annotation(image_path, annotation_path, label_map)\n",
        "                    if annotation_str:\n",
        "                        f.write(f\"{annotation_str}\\n\")\n",
        "\n",
        "    print(f\"Annotation file created successfully at {output_file}\")\n",
        "\n",
        "# Define your dataset path and output file path\n",
        "TRAIN_DIR = \"/content/gdrive/MyDrive/Dataset- -Conference/train\"  # Update this path\n",
        "OUTPUT_FILE = \"/content/gdrive/MyDrive/Dataset- -Conference/train/train.txt\"  # Update this path\n",
        "\n",
        "labels = [\n",
        "    \"SpeedLimit60kmh\",\n",
        "    \"School\",\n",
        "    \"PEDESTRIANCROSSING\",\n",
        "    \"SharpBendToTheLeft\",\n",
        "    \"UTurn\",\n",
        "    \"speedlimit80kmh\",\n",
        "    \"NoOvertaking\",\n",
        "    \"SharpBendToTheRight\",\n",
        "    \"SideRoadLeft\",\n",
        "    \"SideRoadRight\",\n",
        "    \"speedlimit40kmh\",\n",
        "    \"NarrowBridge\",\n",
        "    \"RoadHump\",\n",
        "    \"nouseofhorn\",\n",
        "    \"Crossroads\"\n",
        "]\n",
        "\n",
        "label_map = {i + 1: label for i, label in enumerate(labels)}\n",
        "\n",
        "generate_annotation_file(TRAIN_DIR, OUTPUT_FILE, label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PtMiqrO2FQ3",
        "outputId": "ce030580-3e0e-4237-b0b5-b07eb28e9932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotation file created successfully at /content/gdrive/MyDrive/Dataset- -Conference/train/train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpQevwFopNJ8",
        "outputId": "d4a5428d-8b65-4d20-f80c-d9028e86ed63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "create_tfrecord(TRAIN_SET_FILE, os.path.join(TFRECORD_DIR, \"train.tfrecord\"), SAMPLES_PER_FILE)\n",
        "# due to the storage limitation on Colab, we skip the testing set\n",
        "#create_tfrecord(TEST_SET_FILE, os.path.join(TFRECORD_DIR, \"test.tfrecord\"), SAMPLES_PER_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating /content/gdrive/MyDrive/Dataset- -Conference/train/train.txt at /content/gdrive/MyDrive/Dataset- -Conference/tfrecords/train.tfrecord\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "the filename cannot be resolved",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-adb20688fede>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_SET_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTFRECORD_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLES_PER_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# due to the storage limitation on Colab, we skip the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#create_tfrecord(TEST_SET_FILE, os.path.join(TFRECORD_DIR, \"test.tfrecord\"), SAMPLES_PER_FILE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-41943479a5d7>\u001b[0m in \u001b[0;36mcreate_tfrecord\u001b[0;34m(dataset_path, output_path, samples_per_file)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_to_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtfwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-41943479a5d7>\u001b[0m in \u001b[0;36mfilename_to_annotation\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"top\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bottom\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the filename cannot be resolved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: the filename cannot be resolved"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import io\n",
        "import difflib\n",
        "\n",
        "# Define class names and their corresponding IDs\n",
        "CLASS_NAMES = [\n",
        "    'SpeedLimit60kmh', 'School', 'PEDESTRIANCROSSING', 'SharpBendToTheLeft',\n",
        "    'UTurn', 'speedlimit80kmh', 'NoOvertaking', 'SharpBendToTheRight',\n",
        "    'SideRoadLeft', 'SideRoadRight', 'speedlimit40kmh', 'NarrowBridge',\n",
        "    'RoadHump', 'nouseofhorn', 'Crossroads'\n",
        "]\n",
        "\n",
        "CLASS_DICT = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
        "\n",
        "# Helper function to find the closest class name\n",
        "def closest_class_name(class_name):\n",
        "    closest_match = difflib.get_close_matches(class_name, CLASS_DICT.keys(), n=1, cutoff=0.6)\n",
        "    return closest_match[0] if closest_match else None\n",
        "\n",
        "# Helper function to create TFRecords\n",
        "def create_tf_example(img_path, annotation_path):\n",
        "    # Read the image\n",
        "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
        "        encoded_image = fid.read()\n",
        "\n",
        "    image = Image.open(io.BytesIO(encoded_image))\n",
        "    width, height = image.size\n",
        "\n",
        "    # Parse XML annotation\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    filename = root.find('filename').text\n",
        "    xmin_list = []\n",
        "    ymin_list = []\n",
        "    xmax_list = []\n",
        "    ymax_list = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        closest_name = closest_class_name(class_name)\n",
        "        if closest_name is None:\n",
        "            continue\n",
        "\n",
        "        classes_text.append(closest_name.encode('utf8'))\n",
        "        classes.append(CLASS_DICT[closest_name])\n",
        "\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = int(bndbox.find('xmin').text)\n",
        "        ymin = int(bndbox.find('ymin').text)\n",
        "        xmax = int(bndbox.find('xmax').text)\n",
        "        ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "        xmin_list.append(float(xmin) / width)\n",
        "        ymin_list.append(float(ymin) / height)\n",
        "        xmax_list.append(float(xmax) / width)\n",
        "        ymax_list.append(float(ymax) / height)\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode('utf8')])),\n",
        "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode('utf8')])),\n",
        "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image])),\n",
        "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'png'])),\n",
        "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin_list)),\n",
        "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin_list)),\n",
        "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax_list)),\n",
        "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax_list)),\n",
        "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
        "    }))\n",
        "\n",
        "    return tf_example\n",
        "\n",
        "def create_tfrecords(train_dir, output_path):\n",
        "    writer = tf.io.TFRecordWriter(output_path)\n",
        "\n",
        "    image_dir = os.path.join(train_dir, 'images')\n",
        "    annotation_dir = os.path.join(train_dir, 'annotation')\n",
        "\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith('.png'):\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            annotation_path = os.path.join(annotation_dir, filename.replace('.png', '.xml'))\n",
        "\n",
        "            if not os.path.exists(annotation_path):\n",
        "                continue\n",
        "\n",
        "            tf_example = create_tf_example(img_path, annotation_path)\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "# Run the function\n",
        "train_dir = '/content/gdrive/MyDrive/Dataset- -Conference/val'\n",
        "output_path = '/content/gdrive/MyDrive/Dataset- -Conference/val/val.tfrecord'\n",
        "create_tfrecords(train_dir, output_path)"
      ],
      "metadata": {
        "id": "iAqFld_8-UM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def convert_dataset_to_file_list(dataset_dir, output_file):\n",
        "    with open(output_file, 'w') as f:\n",
        "        for subset in ['train', 'val', 'test']:\n",
        "            image_dir = os.path.join(dataset_dir, subset, 'images')\n",
        "            annotation_dir = os.path.join(dataset_dir, subset, 'annotation')\n",
        "\n",
        "            if not os.path.exists(image_dir) or not os.path.exists(annotation_dir):\n",
        "                print(f\"Subset directory {subset} does not exist or is incomplete.\")\n",
        "                continue\n",
        "\n",
        "            files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "            for filename in files:\n",
        "                image_path = os.path.join(subset, 'images', filename)\n",
        "                annotation_path = os.path.join(subset, 'annotation', os.path.splitext(filename)[0] + '.xml')\n",
        "\n",
        "                if not os.path.exists(os.path.join(dataset_dir, annotation_path)):\n",
        "                    print(f\"Annotation file for {filename} does not exist. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                f.write(f\"{image_path}\\n\")\n",
        "\n",
        "    print(f\"File list created successfully at {output_file}\")\n",
        "\n",
        "# Define your dataset path and output file path\n",
        "%mkdir tfrecords\n",
        "DATASET_DIR = \"/content/gdrive/MyDrive/Dataset- -Conference\"  # Update this path\n",
        "OUTPUT_FILE = \"/content/tfrecords/train.txt\"  # Update this path\n",
        "\n",
        "convert_dataset_to_file_list(DATASET_DIR, OUTPUT_FILE)"
      ],
      "metadata": {
        "id": "88vA7tot81fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "for example in tf.python_io.tf_record_iterator(\"/content/gdrive/MyDrive/Dataset- -Conference/val/val.tfrecord\"):\n",
        "  print(tf.train.Example.FromString(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "c2rYWEiwCOEX",
        "outputId": "7cba99cc-ebf9-4426-e777-84f9ed70b7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'python_io'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-973a91659e0e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Dataset- -Conference/val/val.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'python_io'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SyUckwHpNKA"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baYTXXhSpNKB"
      },
      "source": [
        "## Create the config YAML file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ZLKoffpNKC"
      },
      "source": [
        "CONFIG_DIR = os.path.join(PROJ_DIR, \"configs\")\n",
        "CONFIG_FILE = os.path.join(CONFIG_DIR, \"default.yaml\")\n",
        "if not os.path.exists(CONFIG_DIR):\n",
        "    os.mkdir(CONFIG_DIR)\n",
        "\n",
        "\n",
        "labels = [\n",
        "    \"SpeedLimit60kmh\",\n",
        "    \"School\",\n",
        "    \"PEDESTRIANCROSSING\",\n",
        "    \"SharpBendToTheLeft\",\n",
        "    \"UTurn\",\n",
        "    \"speedlimit80kmh\",\n",
        "    \"NoOvertaking\",\n",
        "    \"SharpBendToTheRight\",\n",
        "    \"SideRoadLeft\",\n",
        "    \"SideRoadRight\",\n",
        "    \"speedlimit40kmh\",\n",
        "    \"NarrowBridge\",\n",
        "    \"RoadHump\",\n",
        "    \"nouseofhorn\",\n",
        "    \"Crossroads\"\n",
        "]\n",
        "\n",
        "\n",
        "label_map = {i + 1: label for i, label in enumerate(labels)}\n",
        "\n",
        "label_map_str = \", \".join([f\"{k}: {v}\" for k, v in label_map.items()])\n",
        "\n",
        "config_text = f\"\"\"\n",
        "image_size: 1024x1024\n",
        "num_classes: {len(labels)}\n",
        "label_map: {{{label_map_str}}}\n",
        "input_rand_hflip: true\n",
        "jitter_min: 0.8\n",
        "jitter_max: 1.2\n",
        "\"\"\"\n",
        "\n",
        "with open(CONFIG_FILE, \"w\") as fwrite:\n",
        "    fwrite.write(config_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7pXPzp2pNKM"
      },
      "source": [
        "## Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHf5mt-BpNKN"
      },
      "source": [
        "CKPT = MODEL\n",
        "\n",
        "#TRAIN_SET = os.path.join(TFRECORD_DIR, \"train.tfrecord-*\")\n",
        "#VAL_SET = os.path.join(TFRECORD_DIR, \"val.tfrecord-*\")\n",
        "TRAIN_SET = \"/content/gdrive/MyDrive/Dataset- -Conference/tfrecords/train.tfrecord-train.tfrecord\"\n",
        "VAL_SET = \"/content/gdrive/MyDrive/Dataset- -Conference/tfrecords/val.tfrecord-val.tfrecord\"\n",
        "MODEL_DIR_TMP = os.path.join(PROJ_DIR, \"tmp\", f\"{MODEL}-finetune\")\n",
        "TRAIN_NUM_EXAMPLES = 5000\n",
        "EVAL_NUM_EXAMPLES = 5000\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11FqXpdypNKH"
      },
      "source": [
        "## Remove the previous checkpoint (if exists) before restarting the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98zfUtXdpNKH"
      },
      "source": [
        "if os.path.exists(MODEL_DIR_TMP):\n",
        "    !rm -rf {MODEL_DIR_TMP}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmd4fRhupNKQ"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SET = \"/content/gdrive/MyDrive/Dataset- -Conference/train/train.tfrecord\"\n",
        "VAL_SET = \"/content/gdrive/MyDrive/Dataset- -Conferenc/val/val.tfrecord\""
      ],
      "metadata": {
        "id": "j5dPifQH-rn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0NURMVIpNKR",
        "outputId": "d2a1c9a5-579f-4c14-a6c1-8d08a9dec3cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/automl/efficientdet/main.py \\\n",
        "    --mode=train_and_eval \\\n",
        "    --train_file_pattern={TRAIN_SET} \\\n",
        "    --val_file_pattern={VAL_SET} \\\n",
        "    --model_name={MODEL} \\\n",
        "    --model_dir={MODEL_DIR_TMP} \\\n",
        "    --ckpt={CKPT} \\\n",
        "    --train_batch_size={BATCH_SIZE} \\\n",
        "    --eval_batch_size={BATCH_SIZE} \\\n",
        "    --num_epochs={EPOCHS} \\\n",
        "    --num_examples_per_epoch={TRAIN_NUM_EXAMPLES} \\\n",
        "    --eval_samples={EVAL_NUM_EXAMPLES} \\\n",
        "    --hparams={CONFIG_FILE}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-14 16:16:15.220913: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-14 16:16:15.221152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-14 16:16:15.224729: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-14 16:16:16.753057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "FATAL Flags parsing error: Unknown command line flag 'Conference/train/train.tfrecord'\n",
            "Pass --helpshort or --helpfull to see help on flags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp72sGT9pNKX"
      },
      "source": [
        "# Model inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNcFsIY4pNKZ"
      },
      "source": [
        "## Export the model (from checkpoint to saved model format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGt6sHeKpNKZ"
      },
      "source": [
        "MODEL_DIR_EXPORT = os.path.join(PROJ_DIR, \"models\", f\"{MODEL}-finetune\")\n",
        "\n",
        "MIN_SCORE_THRESHOLD = 0.1\n",
        "\n",
        "!python /content/automl/efficientdet/main_inspect.py \\\n",
        "    --runmode=saved_model \\\n",
        "    --model_name={MODEL} \\\n",
        "    --ckpt_path={MODEL_DIR_TMP} \\\n",
        "    --saved_model_dir={MODEL_DIR_EXPORT} \\\n",
        "    --min_score_thresh={MIN_SCORE_THRESHOLD} \\\n",
        "    --hparams={CONFIG_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_inspect.py --runmode=infer \\\n",
        "  --model_name=efficientdet-d0   --ckpt_path=efficientdet-d0 \\\n",
        "  --hparams=voc_config.yaml  \\\n",
        "  --input_image=img.png --output_image_dir=/tmp/"
      ],
      "metadata": {
        "id": "2ZID5b1PU_km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3lztbLrpNKd"
      },
      "source": [
        "## Run inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juzBFa8QpNKd"
      },
      "source": [
        "TEST_IMAGE_DIR = os.path.join(DATASET_DIR, \"ccpd_base\")\n",
        "TEST_IMAGE_FILES = os.path.join(TEST_IMAGE_DIR, \"*.jpg\")\n",
        "#TEST_IMAGE_FILES = os.path.join(TEST_IMAGE_DIR, \"09-1_13-81&477_603&621-578&604_81&621_106&494_603&477-0_0_24_31_3_27_30-102-134.jpg\")\n",
        "\n",
        "RESULT_DIR = os.path.join(PROJ_DIR, \"results\")\n",
        "if not os.path.exists(RESULT_DIR):\n",
        "    os.mkdir(RESULT_DIR)\n",
        "\n",
        "# we can set a higher threshold here\n",
        "# however, the results are already filtered with the previous threshold during the model exporting\n",
        "MIN_SCORE_THRESHOLD = 0.5\n",
        "\n",
        "!python /content/automl/efficientdet/main_inspect.py \\\n",
        "    --runmode=saved_model_infer \\\n",
        "    --saved_model_dir={MODEL_DIR_EXPORT} \\\n",
        "    --model_name={MODEL} \\\n",
        "    --input_image={TEST_IMAGE_FILES} \\\n",
        "    --output_image_dir={RESULT_DIR} \\\n",
        "    --min_score_thresh={MIN_SCORE_THRESHOLD} \\\n",
        "    --hparams={CONFIG_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgO8XZqlCLi9"
      },
      "source": [
        "## Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg88LK7vpNKj"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "MAX_SHOW_RESULTS = 10\n",
        "\n",
        "for i in range(MAX_SHOW_RESULTS):\n",
        "    fname = os.path.join(RESULT_DIR, \"{}.jpg\".format(i))\n",
        "    if os.path.exists(fname):\n",
        "        print(fname)\n",
        "        display(Image(fname))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}